# Neural-Network-solving-mechanics-problem
Данная нейронная сеть решает задачу кинематики. Ответ задачи можно вычислить следующей формулой v_0 *(1 - (sin_alpha)^2)^0.5 * (2 * (H + (v_0^2*sin_alpha^2)/(2*g))/g)^0.5, где v_0 - начальная скорость, sin_alpha - угол между направлением полета и осью x, Н - начальная высота материальной точки, g - гравитационная постоянная. Так как задача нелинейная, то нейронной сети нужно более одного скрытого слоя, поэтому было выбрано 3 скрытых слоя. Функцией активации в данной нейронной сети является Leaky ReLU, так как данная функция легко дифференцируема и легко вычисляется и для вычисления требуется очень мало времени. Также Leaky ReLU является нелинейной функцией поэтому мы можем аппроксимировать другие функции, что не может сделать линейная функция.
Из библиотек использовались: numpy, time, csv. Numpy использовался для быстрого умножения матриц, также используя функции numpy можно короче записывать выражения, так конструкция if - else может быть написана используя numpy.where(). С помощью библиотеки time вычисляется время на выполнение программы. Также используется библиотека csv. Данная библеотека позволяет работать с файлами с расширением .csv в которых записаны данные для тренировки и тестов данной нейронной сети.
Для написания нейронной сети я использовал объектно-ориентированное программирование, чтобы можно было создавать нейронные сети с разным количеством нейронов в слое.
В методе __init__ присвается количество нейронов на каждом слое. После этого, используя функцию numpy.random.normal(), задаются веса между всеми слоями, где первый аргумент - это центр интервала, второй аргумент - это длина интервала, а третий - это размерность (в данном случае это будет матрица). После следует присвоение коэффициента обучения и присвоение функции активации, используя лямбда функцию, в которой используется numpy.where(),  где первый аргумент - это условие, второй - действие, если условие выполнилось, а третий - действие, если условие не выполнилось.
Дальше идет метод train() - основной метод нейронной сети, в котором происходит изменение весов (нейронная сеть обучается). В данном методе, вначале одномерный массив трансформируется в двумерный и транспонируется для дальнейшей операции умножения матриц. После этого происходит матричное умножение входных данных на веса и после к получившимся значениям применяется функция активации. После этого вычитанием от правильного ответа получившегося числаполучам ошибку, после этого происходит распределение ошибки на каждый нейрон каждого слоя. Затем к каждому слою применяется градиент функции активации. И после этих действий изменяются веса, но, чтобы веса не склонялись к каждым входным данным, а обобщал и находил какие-либо отношения входных данных, используется коэфициент обучения, в зависимости от количества входных данных его можно либо увеличивать либо уменьшать.
Следующий метод класса NeuralNetwork это query(). Данный метод пропускает входные данные через все слои и выдает ответ нейронной сети.
После класса инициализируется объект класса NeuralNetwork, также из файла input_train.csv берутся входные данные.
После этого на протяжении n-ого количества эпох тренировки нейронной сети обучение заканчивается.
После этого из файла input_test.csv берутся данные для теста нейронной сети, их ровно 100.
Во время тестирования нейронной сети считается средняя ошибка нейронной сети. И после всех 100 тестов выводится результат теста, а также средняя ошибка в процентах.
И в конце выводится время обучения нейронной сети.


